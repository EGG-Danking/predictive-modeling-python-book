# -*- coding: utf-8 -*-
"""Room Occupancy Classification - SOLUTIONS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y4j6YhxBXosYdbOjuQMaeqg_5wZC_pqT
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install ucimlrepo

import plotly.express as px

"""## Data Loading

https://archive.ics.uci.edu/dataset/357/occupancy+detection
"""

from ucimlrepo import fetch_ucirepo

ds = fetch_ucirepo(id=357)

ds.variables

from pandas import to_datetime, to_numeric

df = ds["data"]["original"].copy()

df.rename(columns={"date": "Timestamp", "Occupancy": "Occupied"}, inplace=True)
df.drop(columns=["id", "Timestamp"], inplace=True)

# drop nulls:
df.dropna(inplace=True)

# clean datatypes / convert to numeric datatypes:
numeric_features = ["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]
df[numeric_features] = df[numeric_features].apply(to_numeric)

# conversion to datetime datatype:
#df["Timestamp"] = to_datetime(df["Timestamp"])

#target = "Occupied"
#df[target] = df[target].map({0: False, 1: True})

print(df.shape)
df.head()

target = "Occupied"

"""## Data Cleaning

### Null Values
"""

#df[target].isna().sum()

#df[df[target].isna()]

#df.dropna(inplace=True)
#print(len(df))



"""### Numeric Datatype Conversion"""

#df["HumidityRatio"].describe()

#df["HumidityRatio"].astype(float).describe()

#from pandas import to_numeric
#
#numeric_features = ["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]
#df[numeric_features] = df[numeric_features].apply(to_numeric, errors="raise")
#df.dtypes

#df.describe()

"""## Data Exploration

### Distribution of the Target
"""

# if imbalanced, we might need to choose a sampling strategy
df[target].value_counts()

#import plotly.express as px
#
#px.violin(df, x=target, box=True, points="all", height=350,
#          title=f"Distribution of {target}")

px.histogram(df, x=target, nbins=5, height=350,
             title="Distribution of Occupancy"
            )

"""### Relationships"""

px.scatter(df, x="Light", y=target, height=350,
           trendline="ols", trendline_color_override="red"
)

px.histogram(df, x="Light", nbins=7, height=350,
             facet_col=target,
            )

px.histogram(df, x="Temperature", nbins=7, height=350,
             facet_col=target, #facet_col_wrap=2
            )

"""### Correlation"""

#features = ["Temperature", "Humidity", "Light", "CO2", "HumidityRatio"]
#print(features)
#
#encoded_features = ["Hour", "Minute"]
#encoded_features += [col for col in df_encoded.columns if col.startswith("Day")]
#print(encoded_features)
#
#all_features = features + encoded_features
#df_encoded[all_features + [target]]

#import plotly.express as px
#
def plot_correlation_matrix(df, method="pearson", height=450):
    """Params: method (str): "spearman" or "pearson". """

    cor_mat = df.corr(method=method, numeric_only=True)

    title= f"{method.title()} Correlation"

    fig = px.imshow(cor_mat,
                    height=height, # title=title,
                    text_auto= ".2f", # round to two decimal places
                    color_continuous_scale="Blues",
                    color_continuous_midpoint=0,
                    labels={"x": "Variable", "y": "Variable"},
    )
    # center title (h/t: https://stackoverflow.com/questions/64571789/)
    fig.update_layout(title={'text': title, 'x':0.485, 'xanchor': 'center'})
    fig.show()

# df.drop(columns=["Hour", "Minute"])
plot_correlation_matrix(df, method="spearman", height=450)

"""highest correlation between features is humidity and humidity ratio. we can probably drop one due to collinearity"""

corr_target = df.corr(numeric_only=True)[target].sort_values(ascending=False)
corr_target

"""## Feature Engineering

### Datetime Features
"""

#px.scatter(df, x="Date", y=target, color=target, height=350)

#from pandas import to_datetime
#
#date_col = "Timestamp"
#
#if date_col in df.columns:
#    df[date_col] = to_datetime(df[date_col])
#
#    df["Date"] = df[date_col].dt.date
#    #df["Year"] = df[date_col].dt.year
#    #df["Month"] = df[date_col].dt.month
#    #df["Day"] = df[date_col].dt.day
#    #df["DayOfWeek"] = df[date_col].dt.dayofweek
#    df["DayName"] = df[date_col].dt.day_name()
#    df["Hour"] = df[date_col].dt.hour
#    df["Minute"] = df[date_col].dt.minute
#
#    #df.drop(columns=[date_col], inplace=True)
#
#
#df.head()

#px.histogram(df, x="Date", height=350, color=target,
#             facet_row=target, #facet_col_wrap=2,
#             title="Occupancy by Date"
#             )

#px.histogram(df, x="DayName", height=350, color=target,
#             facet_row=target,
#             title="Occupancy by Day of Week"
#             )

#px.histogram(df, x="Hour", height=350, color=target,
#             title="Occupancy by Hour",
#             facet_row=target,
#             )

#fig = px.histogram(df, x="DayName", color="Occupied",  height=350,
#                   title="Occupancy by Day Name",
#                   category_orders={"DayName": ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]})
#fig.update_layout(barmode='stack')
#fig.show()

"""Weird that we have more observations on Monday and Tuesday? Unless there were more mondays and tuesdays involved.

Maybe we can sample the same number of responses for each day of week.

Need to learn more about how this data was collected (refer to dataset description and metadata).
"""

# count number of dates for each day of week:
#df.groupby("DayName")["Date"].value_counts()

"""## Data Encoding

### One Hot Encoding
"""

#from pandas import get_dummies as one_hot_encode
#
#one_hot_encode(df, columns=["DayName"], prefix="Day").head()

#from pandas import get_dummies as one_hot_encode
#
#if "DayName" in df.columns:
#    df_encoded = df.copy()
#    df_encoded = one_hot_encode(df_encoded, columns=["DayName"], prefix="Day", dtype=int)
#    #df_encoded = one_hot_encode(df_encoded, columns=["Hour"], prefix="H", dtype=int)
#    #df_encoded = one_hot_encode(df_encoded, columns=["Minute"], prefix="M", dtype=int)
#    df_encoded.drop(columns=["Timestamp", "Date"], inplace=True)
#
#df_encoded.head()

"""## X/Y Split"""

df.columns.tolist()

target = "Occupied"
y = df[target].copy()

x = df.drop(columns=[target]).copy() #, "Timestamp", "Date"
print("X:", x.shape)
print("Y:", y.shape)

#y

#x.drop(columns=[col for col in x.columns if "Day" in col], inplace=True)
#x.drop(columns=["Hour", "Minute"], inplace=True)
#x.head()

"""## Feature Scaling"""

# x.describe().T[["min", "max"]]

#x.max().sort_values(ascending=False)

x_scaled = (x - x.mean(axis=0)) / x.std(axis=0)
x_scaled.describe().T[["mean", "std"]]

"""## Train Test Split"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x_scaled, y,
                                                    test_size=0.2,
                                                    random_state=99)
print("TRAIN:", x_train.shape, y_train.shape)
print("TEST:", x_test.shape, y_test.shape)

"""## Model Training"""

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(random_state=99)
model.fit(x_train, y_train)

"""Examining coeficients:"""

model.coef_.shape

from pandas import Series

coef = Series(model.coef_[0], index=x_train.columns)
coef.sort_values(ascending=False)

"""## Model Eval"""

y_pred = model.predict(x_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

"""### Confusion Matrix"""

from sklearn.metrics import confusion_matrix
import plotly.express as px

def plot_confusion_matrix(y_true, y_pred, height=450, showscale=False, title=None, subtitle=None):
    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html
    # Confusion matrix whose i-th row and j-th column
    # ... indicates the number of samples with
    # ... true label being i-th class (ROW)
    # ... and predicted label being j-th class (COLUMN)
    cm = confusion_matrix(y_true, y_pred)

    class_names = sorted(y_test.unique().tolist())

    cm = confusion_matrix(y_test, y_pred, labels=class_names)

    title = title or "Confusion Matrix"
    if subtitle:
        title += f"<br><sup>{subtitle}</sup>"

    fig = px.imshow(cm, x=class_names, y=class_names, height=height,
                    labels={"x": "Predicted", "y": "Actual"},
                    color_continuous_scale="Blues", text_auto=True,
    )
    fig.update_layout(title={'text': title, 'x':0.485, 'xanchor': 'center'})
    fig.update_coloraxes(showscale=showscale)

    fig.show()


subtitle = f"Occupancy Classification Model: {model.__class__.__name__}"
plot_confusion_matrix(y_test, y_pred, subtitle=subtitle, height=350)

"""## Complexity vs Performance"""

features = []

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from pandas import Series

def train_eval_logistic(df, target="Occupied", features=[]):
    if not any(features):
        features = df.drop(columns=[target]).columns.tolist()
    print("FEATURES:", features)

    x = df[features].copy()
    print("X:", x.shape)

    y = df[target].copy()
    print("Y:", y.shape)

    # SCALING:
    x_scaled = (x - x.mean(axis=0)) / x.std(axis=0)

    # TRAIN / TEST SPLIT:
    x_train, x_test, y_train, y_test = train_test_split(x_scaled, y,
                                                    test_size=0.2,
                                                    random_state=99)
    # MODEL TRAINING:
    model = LogisticRegression(random_state=99)
    model.fit(x_train, y_train)

    print("COEFS:")
    coef = Series(model.coef_[0], index=x_train.columns)
    print(coef.sort_values(ascending=False))

    # PREDS AND EVAL:
    y_pred = model.predict(x_test)

    print(classification_report(y_test, y_pred))


train_eval_logistic(df)

train_eval_logistic(df, features=["Light"])

train_eval_logistic(df, features=["Temperature"])

train_eval_logistic(df, features=["CO2"])

train_eval_logistic(df, features=["HumidityRatio"])